name: Data pipeline for loading json files in BigQuery tables

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 7 * * 1' 

jobs:
  run-query:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Log in to Google Cloud
      uses: 'google-github-actions/auth@v2'
      with:
        credentials_json: '${{ secrets.GOOGLE_CLOUD_CREDENTIALS }}'

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.13'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install dbt-bigquery dbt-core

    - name: List project files
      run: |
        echo "Listing files in the root directory"
          ls -R
    
    - name: Authenticate to Google Cloud
      run: |
        echo "${{ secrets.GOOGLE_CLOUD_CREDENTIALS }}" > "${{ github.workspace }}/gha-creds.json"
        export GOOGLE_APPLICATION_CREDENTIALS="${{ github.workspace }}/gha-creds.json"

    - name: List contents of directory
      run: |
        ls -al /home/runner/work/meetup_dbt/meetup_dbt/

    # - name: Run basic dbt model
    #   run: |
    #     dbt run --models stg_venues