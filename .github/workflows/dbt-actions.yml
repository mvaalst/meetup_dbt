name: Data pipeline for loading json files in BigQuery tables

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 7 * * 1' 

jobs:
  run-query:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Log in to Google Cloud
      uses: 'google-github-actions/auth@v2'
      with:
        credentials_json: '${{ secrets.GOOGLE_CLOUD_CREDENTIALS }}'
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.13'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install google-cloud-bigquery google-auth pandas db-dtypes dbt-bigquery dbt-core
    
    # Step 4: Set up DBT profiles (credentials to connect to the database)
    - name: Configure DBT profile
      run: |
        mkdir -p ~/meetup_dbt/meetup_dbt
        echo "base-dbt-profile:
          target: dbt
          outputs:
            dbt:
              threads: 4
              type: bigquery
              method: service-account
              project: striped-torus-445510-c9
              schema: dbt
              location: US
        " > ~/meetup_dbt/meetup_dbt/profiles.yml

    - name: Display profiles.yml content
      run: cat ~/meetup_dbt/meetup_dbt/profiles.yml

    - name: Authenticate to Google Cloud
      run: |
        echo "${{ secrets.GOOGLE_CLOUD_CREDENTIALS }}" > "${{ github.workspace }}/gha-creds.json"
        export GOOGLE_APPLICATION_CREDENTIALS="${{ github.workspace }}/gha-creds.json"
    
    - name: Run basic dbt model
      run: |
        dbt run --profiles-dir .